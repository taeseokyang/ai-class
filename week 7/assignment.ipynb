{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  DSA dataset을 이용해서, 정상데이터(Lying)과 비정상데이터 설정 (다른 jumping이 아니라 activity 선택)\n",
    "\n",
    "- Encoder와 Decoder의 구조가 같은 오토인코더로 지난주차와 동일하게 이상치 탐지\n",
    "\n",
    "- Encoder와 Decoder의 구조가 다른 비대칭형 뉴런수로 성능 확인\n",
    "\n",
    "- DAE를 사용하여 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 00:25:47.799141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datas/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[(df['activity'] == 'lyingRigh') | (df['activity'] == 'lyingBack')]\n",
    "abnormal = df[df['activity'] == 'jumping']\n",
    "\n",
    "X_normal = normal.drop(columns=['activity']).select_dtypes(include=[np.number])\n",
    "X_abnormal = abnormal.drop(columns=['activity']).select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 00:28:10.218722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 112ms/step - loss: 1.3070 - val_loss: 0.9952\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2807 - val_loss: 0.9786\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2559 - val_loss: 0.9622\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2306 - val_loss: 0.9455\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2023 - val_loss: 0.9281\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1719 - val_loss: 0.9097\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1391 - val_loss: 0.8907\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1061 - val_loss: 0.8713\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0734 - val_loss: 0.8519\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.0430 - val_loss: 0.8333\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0158 - val_loss: 0.8154\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9928 - val_loss: 0.7991\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9735 - val_loss: 0.7843\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9581 - val_loss: 0.7714\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9454 - val_loss: 0.7604\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9353 - val_loss: 0.7511\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9269 - val_loss: 0.7435\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9198 - val_loss: 0.7372\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9138 - val_loss: 0.7322\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9085 - val_loss: 0.7281\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9039 - val_loss: 0.7249\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8996 - val_loss: 0.7223\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.8957 - val_loss: 0.7203\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8923 - val_loss: 0.7188\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8891 - val_loss: 0.7176\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8863 - val_loss: 0.7166\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8839 - val_loss: 0.7157\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8815 - val_loss: 0.7150\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8794 - val_loss: 0.7141\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8775 - val_loss: 0.7132\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8756 - val_loss: 0.7120\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8739 - val_loss: 0.7107\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8723 - val_loss: 0.7094\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8708 - val_loss: 0.7080\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8695 - val_loss: 0.7067\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8682 - val_loss: 0.7054\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8669 - val_loss: 0.7043\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8655 - val_loss: 0.7035\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8642 - val_loss: 0.7027\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8631 - val_loss: 0.7020\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8621 - val_loss: 0.7013\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8612 - val_loss: 0.7004\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8602 - val_loss: 0.6993\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8593 - val_loss: 0.6981\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8583 - val_loss: 0.6969\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8574 - val_loss: 0.6957\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8565 - val_loss: 0.6947\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8557 - val_loss: 0.6938\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8550 - val_loss: 0.6929\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8542 - val_loss: 0.6921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff62b562160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normal_scaled = scaler.fit_transform(X_normal)\n",
    "X_abnormal_scaled = scaler.transform(X_abnormal)\n",
    "\n",
    "def build_symmetric_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    encoded = layers.Dense(64, activation='relu')(input_layer)\n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "autoencoder_symmetric = build_symmetric_autoencoder(X_normal_scaled.shape[1])\n",
    "autoencoder_symmetric.fit(X_normal_scaled, X_normal_scaled, epochs=50, batch_size=256, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 98ms/step - loss: 1.3067 - val_loss: 0.9870\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.2819 - val_loss: 0.9662\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.2502 - val_loss: 0.9379\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.2070 - val_loss: 0.9018\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1521 - val_loss: 0.8614\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0921 - val_loss: 0.8226\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0371 - val_loss: 0.7935\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9968 - val_loss: 0.7744\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9718 - val_loss: 0.7614\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9558 - val_loss: 0.7510\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.9438 - val_loss: 0.7416\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9340 - val_loss: 0.7329\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9270 - val_loss: 0.7265\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9210 - val_loss: 0.7219\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9162 - val_loss: 0.7189\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.9113 - val_loss: 0.7169\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9064 - val_loss: 0.7144\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9012 - val_loss: 0.7120\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8966 - val_loss: 0.7098\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8929 - val_loss: 0.7081\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8898 - val_loss: 0.7068\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8870 - val_loss: 0.7059\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8847 - val_loss: 0.7047\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.8827 - val_loss: 0.7036\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8802 - val_loss: 0.7029\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8784 - val_loss: 0.7016\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8766 - val_loss: 0.6998\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8752 - val_loss: 0.6983\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8738 - val_loss: 0.6978\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8722 - val_loss: 0.6985\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8705 - val_loss: 0.6997\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8693 - val_loss: 0.6999\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8682 - val_loss: 0.6988\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8671 - val_loss: 0.6969\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8657 - val_loss: 0.6960\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8646 - val_loss: 0.6959\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8638 - val_loss: 0.6958\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.8631 - val_loss: 0.6958\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8625 - val_loss: 0.6951\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8619 - val_loss: 0.6940\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8613 - val_loss: 0.6924\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8605 - val_loss: 0.6921\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8600 - val_loss: 0.6921\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8595 - val_loss: 0.6921\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8591 - val_loss: 0.6921\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8586 - val_loss: 0.6920\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8581 - val_loss: 0.6915\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8576 - val_loss: 0.6914\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8570 - val_loss: 0.6917\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8563 - val_loss: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff639f4d8b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_asymmetric_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    encoded = layers.Dense(128, activation='relu')(input_layer) \n",
    "    encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "    decoded = layers.Dense(128, activation='relu')(encoded) \n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "autoencoder_asymmetric = build_asymmetric_autoencoder(X_normal_scaled.shape[1])\n",
    "autoencoder_asymmetric.fit(X_normal_scaled, X_normal_scaled, epochs=50, batch_size=256, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 74ms/step - loss: 1.3183 - val_loss: 1.0119\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.2913 - val_loss: 0.9977\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2669 - val_loss: 0.9831\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2422 - val_loss: 0.9685\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2157 - val_loss: 0.9536\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.1868 - val_loss: 0.9382\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1556 - val_loss: 0.9225\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1232 - val_loss: 0.9064\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0905 - val_loss: 0.8900\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0592 - val_loss: 0.8735\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0307 - val_loss: 0.8567\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0055 - val_loss: 0.8403\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.9837 - val_loss: 0.8244\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9657 - val_loss: 0.8093\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9512 - val_loss: 0.7955\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.9392 - val_loss: 0.7833\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.9297 - val_loss: 0.7725\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.9217 - val_loss: 0.7631\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9149 - val_loss: 0.7553\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9094 - val_loss: 0.7485\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9045 - val_loss: 0.7426\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.9001 - val_loss: 0.7376\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8962 - val_loss: 0.7334\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8929 - val_loss: 0.7297\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8897 - val_loss: 0.7266\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8868 - val_loss: 0.7238\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8843 - val_loss: 0.7215\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8818 - val_loss: 0.7193\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8795 - val_loss: 0.7175\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8772 - val_loss: 0.7158\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8752 - val_loss: 0.7142\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8735 - val_loss: 0.7127\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8718 - val_loss: 0.7112\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8702 - val_loss: 0.7097\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8687 - val_loss: 0.7083\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8673 - val_loss: 0.7069\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8660 - val_loss: 0.7056\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8647 - val_loss: 0.7044\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.8634 - val_loss: 0.7033\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8622 - val_loss: 0.7022\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8611 - val_loss: 0.7012\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8601 - val_loss: 0.7001\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8591 - val_loss: 0.6990\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8582 - val_loss: 0.6979\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8573 - val_loss: 0.6968\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8565 - val_loss: 0.6957\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.8557 - val_loss: 0.6947\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8548 - val_loss: 0.6937\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8541 - val_loss: 0.6927\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8533 - val_loss: 0.6917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff61c058970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def build_dae_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    noisy_input = layers.GaussianNoise(0.1)(input_layer) \n",
    "    encoded = layers.Dense(64, activation='relu')(noisy_input)\n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "autoencoder_dae = build_dae_autoencoder(X_normal_scaled.shape[1])\n",
    "autoencoder_dae.fit(X_normal_scaled, X_normal_scaled, epochs=50, batch_size=256, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 985us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 976us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 925us/step\n",
      "15/15 [==============================] - 0s 918us/step\n"
     ]
    }
   ],
   "source": [
    "def calculate_reconstruction_error(autoencoder, X_normal_scaled, X_abnormal_scaled):\n",
    "    normal_reconstructed = autoencoder.predict(X_normal_scaled)\n",
    "    abnormal_reconstructed = autoencoder.predict(X_abnormal_scaled)\n",
    "    \n",
    "    normal_reconstruction_error = np.mean(np.square(X_normal_scaled - normal_reconstructed), axis=1)\n",
    "    abnormal_reconstruction_error = np.mean(np.square(X_abnormal_scaled - abnormal_reconstructed), axis=1)\n",
    "    \n",
    "    return normal_reconstruction_error, abnormal_reconstruction_error\n",
    "\n",
    "normal_reconstruction_error_symmetric, abnormal_reconstruction_error_symmetric = calculate_reconstruction_error(autoencoder_symmetric, X_normal_scaled, X_abnormal_scaled)\n",
    "normal_reconstruction_error_asymmetric, abnormal_reconstruction_error_asymmetric = calculate_reconstruction_error(autoencoder_asymmetric, X_normal_scaled, X_abnormal_scaled)\n",
    "normal_reconstruction_error_dae, abnormal_reconstruction_error_dae = calculate_reconstruction_error(autoencoder_dae, X_normal_scaled, X_abnormal_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_symmetric = np.percentile(normal_reconstruction_error_symmetric, 95)\n",
    "threshold_asymmetric = np.percentile(normal_reconstruction_error_asymmetric, 95)\n",
    "threshold_dae = np.percentile(normal_reconstruction_error_dae, 95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Symmetric Autoencoder): 96.67%\n",
      "Accuracy (Asymmetric Autoencoder): 96.67%\n",
      "Accuracy (Denoising Autoencoder): 96.67%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(normal_error, abnormal_error, threshold):\n",
    "    y_true = np.concatenate([np.zeros(len(normal_error)), np.ones(len(abnormal_error))])\n",
    "    y_pred = np.concatenate([ (normal_error > threshold).astype(int), (abnormal_error > threshold).astype(int) ])\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_symmetric = calculate_accuracy(normal_reconstruction_error_symmetric, abnormal_reconstruction_error_symmetric, threshold_symmetric)\n",
    "accuracy_asymmetric = calculate_accuracy(normal_reconstruction_error_asymmetric, abnormal_reconstruction_error_asymmetric, threshold_asymmetric)\n",
    "accuracy_dae = calculate_accuracy(normal_reconstruction_error_dae, abnormal_reconstruction_error_dae, threshold_dae)\n",
    "\n",
    "print(f'Accuracy (Symmetric Autoencoder): {accuracy_symmetric * 100:.2f}%')\n",
    "print(f'Accuracy (Asymmetric Autoencoder): {accuracy_asymmetric * 100:.2f}%')\n",
    "print(f'Accuracy (Denoising Autoencoder): {accuracy_dae * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
