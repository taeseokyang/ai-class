{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st 실습\n",
    "\n",
    "PCA를 이용해서 diabates 적용해보기\n",
    "(n수는 자유)\n",
    "\n",
    "- 2nd AE 실습\n",
    "\n",
    "(수정된 신용카드 거래 소스올리면, 그걸 해보고 수행한후 응용해서 아래 실습)\n",
    "\n",
    "1. DSA데이터에서 \n",
    "lyingRigh                  480\n",
    "lyingBack                  480\n",
    "을 정상 (normal) jumping(abnormal)을 비정상 데이터로 사용\n",
    "\n",
    "2. 두개 (lying+jumping) activity를 섞어서 test \n",
    "\n",
    "3. lying만 가지고 훈련하여 AE 구축\n",
    "\n",
    "4. 테스트 데이터(lying+jumping)AE에 넣어서 Reconstruction error(입력/출력차이)를 구함\n",
    "\n",
    "5. 적당한 threshold값으로 분류수행\n",
    "\n",
    "6. accuracy를 구함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 23:48:51.502534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "df = pd.read_csv(\"datas/diabetes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75694707, -1.11174258],\n",
       "       [ 1.50742148,  0.55940565],\n",
       "       [-0.65082201, -1.92957633],\n",
       "       ...,\n",
       "       [ 0.57408846, -0.03381634],\n",
       "       [ 0.17269908, -1.32289215],\n",
       "       [ 1.32126715,  1.02748861]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.756947</td>\n",
       "      <td>-1.111743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.507421</td>\n",
       "      <td>0.559406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.650822</td>\n",
       "      <td>-1.929576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.587398</td>\n",
       "      <td>1.065075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.483374</td>\n",
       "      <td>2.359563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0 -1.756947 -1.111743\n",
       "1  1.507421  0.559406\n",
       "2 -0.650822 -1.929576\n",
       "3  1.587398  1.065075\n",
       "4 -2.483374  2.359563"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pca_df = pd.DataFrame(pca_result)\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26138907, 0.19714578])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datas/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9.120000e+03</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9.120000e+03</td>\n",
       "      <td>9120.000000</td>\n",
       "      <td>9120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.765766</td>\n",
       "      <td>14.625536</td>\n",
       "      <td>3.602974</td>\n",
       "      <td>17.807013</td>\n",
       "      <td>2.454290</td>\n",
       "      <td>0.305587</td>\n",
       "      <td>-0.811036</td>\n",
       "      <td>1.801847</td>\n",
       "      <td>-3.704204</td>\n",
       "      <td>2.049747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111347</td>\n",
       "      <td>1.818862e-02</td>\n",
       "      <td>0.105897</td>\n",
       "      <td>-0.055440</td>\n",
       "      <td>0.064504</td>\n",
       "      <td>0.169687</td>\n",
       "      <td>-0.052866</td>\n",
       "      <td>7.624694e-03</td>\n",
       "      <td>0.059342</td>\n",
       "      <td>-0.089861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.758022</td>\n",
       "      <td>11.823448</td>\n",
       "      <td>5.622855</td>\n",
       "      <td>45.188787</td>\n",
       "      <td>3.432895</td>\n",
       "      <td>0.768360</td>\n",
       "      <td>2.201692</td>\n",
       "      <td>4.177165</td>\n",
       "      <td>3.982579</td>\n",
       "      <td>3.908675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362373</td>\n",
       "      <td>2.382393e-02</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.526959</td>\n",
       "      <td>0.346660</td>\n",
       "      <td>0.360190</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>1.903445e-02</td>\n",
       "      <td>0.064059</td>\n",
       "      <td>0.619636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.575660</td>\n",
       "      <td>-4.758700</td>\n",
       "      <td>-99.715000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.011633</td>\n",
       "      <td>-7.826631</td>\n",
       "      <td>-9.782885</td>\n",
       "      <td>-9.703600</td>\n",
       "      <td>-49.941000</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.901760</td>\n",
       "      <td>3.044156e-07</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-3.693948</td>\n",
       "      <td>-0.912397</td>\n",
       "      <td>-0.910830</td>\n",
       "      <td>-1.126000</td>\n",
       "      <td>2.960874e-07</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>-5.111532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.374161</td>\n",
       "      <td>9.523200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>-0.161535</td>\n",
       "      <td>-1.134192</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>-4.837875</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111835</td>\n",
       "      <td>5.683172e-04</td>\n",
       "      <td>0.023839</td>\n",
       "      <td>-0.343123</td>\n",
       "      <td>-0.156271</td>\n",
       "      <td>-0.035821</td>\n",
       "      <td>-0.326125</td>\n",
       "      <td>2.227543e-04</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>-0.402781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.186328</td>\n",
       "      <td>12.549500</td>\n",
       "      <td>5.757900</td>\n",
       "      <td>2.241468</td>\n",
       "      <td>1.497153</td>\n",
       "      <td>0.275042</td>\n",
       "      <td>-0.375678</td>\n",
       "      <td>1.571750</td>\n",
       "      <td>-2.470150</td>\n",
       "      <td>0.737663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184470</td>\n",
       "      <td>1.078612e-02</td>\n",
       "      <td>0.103856</td>\n",
       "      <td>-0.075786</td>\n",
       "      <td>0.086285</td>\n",
       "      <td>0.210825</td>\n",
       "      <td>-0.040447</td>\n",
       "      <td>1.813539e-03</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>-0.092036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.515573</td>\n",
       "      <td>15.843250</td>\n",
       "      <td>7.649075</td>\n",
       "      <td>6.680571</td>\n",
       "      <td>2.584680</td>\n",
       "      <td>0.845410</td>\n",
       "      <td>0.127612</td>\n",
       "      <td>3.005450</td>\n",
       "      <td>-1.279725</td>\n",
       "      <td>1.900426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315962</td>\n",
       "      <td>2.740661e-02</td>\n",
       "      <td>0.165549</td>\n",
       "      <td>0.177076</td>\n",
       "      <td>0.295415</td>\n",
       "      <td>0.422270</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>6.927870e-03</td>\n",
       "      <td>0.083234</td>\n",
       "      <td>0.228493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.713139</td>\n",
       "      <td>93.694000</td>\n",
       "      <td>9.749000</td>\n",
       "      <td>392.898630</td>\n",
       "      <td>19.821671</td>\n",
       "      <td>9.070164</td>\n",
       "      <td>7.051530</td>\n",
       "      <td>41.013000</td>\n",
       "      <td>2.656400</td>\n",
       "      <td>54.332000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969020</td>\n",
       "      <td>3.041940e-01</td>\n",
       "      <td>0.551538</td>\n",
       "      <td>5.035185</td>\n",
       "      <td>1.020691</td>\n",
       "      <td>1.042600</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>2.790198e-01</td>\n",
       "      <td>0.528223</td>\n",
       "      <td>3.560828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T_xacc_mean   T_xacc_max   T_xacc_min   T_xacc_var   T_xacc_std  \\\n",
       "count  9120.000000  9120.000000  9120.000000  9120.000000  9120.000000   \n",
       "mean      7.765766    14.625536     3.602974    17.807013     2.454290   \n",
       "std       3.758022    11.823448     5.622855    45.188787     3.432895   \n",
       "min     -11.575660    -4.758700   -99.715000     0.000135     0.011633   \n",
       "25%       8.374161     9.523200     0.000000     0.036855     0.191977   \n",
       "50%       9.186328    12.549500     5.757900     2.241468     1.497153   \n",
       "75%       9.515573    15.843250     7.649075     6.680571     2.584680   \n",
       "max      10.713139    93.694000     9.749000   392.898630    19.821671   \n",
       "\n",
       "       T_xacc_skew  T_yacc_mean   T_yacc_max   T_yacc_min   T_yacc_var  ...  \\\n",
       "count  9120.000000  9120.000000  9120.000000  9120.000000  9120.000000  ...   \n",
       "mean      0.305587    -0.811036     1.801847    -3.704204     2.049747  ...   \n",
       "std       0.768360     2.201692     4.177165     3.982579     3.908675  ...   \n",
       "min      -7.826631    -9.782885    -9.703600   -49.941000     0.000141  ...   \n",
       "25%      -0.161535    -1.134192     0.172375    -4.837875     0.012121  ...   \n",
       "50%       0.275042    -0.375678     1.571750    -2.470150     0.737663  ...   \n",
       "75%       0.845410     0.127612     3.005450    -1.279725     1.900426  ...   \n",
       "max       9.070164     7.051530    41.013000     2.656400    54.332000  ...   \n",
       "\n",
       "       LL_ymag_min   LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "count  9120.000000  9.120000e+03  9120.000000   9120.000000   9120.000000   \n",
       "mean      0.111347  1.818862e-02     0.105897     -0.055440      0.064504   \n",
       "std       0.362373  2.382393e-02     0.083518      0.526959      0.346660   \n",
       "min      -0.901760  3.044156e-07     0.000552     -3.693948     -0.912397   \n",
       "25%      -0.111835  5.683172e-04     0.023839     -0.343123     -0.156271   \n",
       "50%       0.184470  1.078612e-02     0.103856     -0.075786      0.086285   \n",
       "75%       0.315962  2.740661e-02     0.165549      0.177076      0.295415   \n",
       "max       0.969020  3.041940e-01     0.551538      5.035185      1.020691   \n",
       "\n",
       "       LL_zmag_max  LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "count  9120.000000  9120.000000  9.120000e+03  9120.000000   9120.000000  \n",
       "mean      0.169687    -0.052866  7.624694e-03     0.059342     -0.089861  \n",
       "std       0.360190     0.359712  1.903445e-02     0.064059      0.619636  \n",
       "min      -0.910830    -1.126000  2.960874e-07     0.000544     -5.111532  \n",
       "25%      -0.035821    -0.326125  2.227543e-04     0.014925     -0.402781  \n",
       "50%       0.210825    -0.040447  1.813539e-03     0.042586     -0.092036  \n",
       "75%       0.422270     0.206933  6.927870e-03     0.083234      0.228493  \n",
       "max       1.042600     0.999440  2.790198e-01     0.528223      3.560828  \n",
       "\n",
       "[8 rows x 270 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T_xacc_mean', 'T_xacc_max', 'T_xacc_min', 'T_xacc_var', 'T_xacc_std',\n",
       "       'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min', 'T_yacc_var',\n",
       "       ...\n",
       "       'LL_ymag_std', 'LL_ymag_skew', 'LL_zmag_mean', 'LL_zmag_max',\n",
       "       'LL_zmag_min', 'LL_zmag_var', 'LL_zmag_std', 'LL_zmag_skew', 'activity',\n",
       "       'people'],\n",
       "      dtype='object', length=272)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_xacc_mean     0\n",
       "T_xacc_max      0\n",
       "T_xacc_min      0\n",
       "T_xacc_var      0\n",
       "T_xacc_std      0\n",
       "               ..\n",
       "LL_zmag_var     0\n",
       "LL_zmag_std     0\n",
       "LL_zmag_skew    0\n",
       "activity        0\n",
       "people          0\n",
       "Length: 272, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[(df['activity'] == 'lyingRigh') | (df['activity'] == 'lyingBack')]\n",
    "abnormal = df[df['activity'] == 'jumping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([normal, abnormal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_xacc_mean     float64\n",
      "T_xacc_max      float64\n",
      "T_xacc_min      float64\n",
      "T_xacc_var      float64\n",
      "T_xacc_std      float64\n",
      "                 ...   \n",
      "LL_zmag_var     float64\n",
      "LL_zmag_std     float64\n",
      "LL_zmag_skew    float64\n",
      "activity         object\n",
      "people           object\n",
      "Length: 272, dtype: object\n",
      "     T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
      "960    -4.834646     -4.7185     -4.9049    0.001124    0.033529     0.632141   \n",
      "961    -4.780810     -4.5850     -4.8833    0.003948    0.062835     1.052880   \n",
      "962    -4.804400     -4.7037     -4.8755    0.001482    0.038496     0.735226   \n",
      "963    -4.750563     -4.5696     -4.8977    0.004447    0.066683     0.710263   \n",
      "964    -4.774916     -4.6741     -4.8457    0.001080    0.032868     0.324779   \n",
      "\n",
      "     T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_std  \\\n",
      "960    -0.501018    -0.41744    -0.59561    0.001016  ...     0.000986   \n",
      "961    -0.480601    -0.40372    -0.63184    0.001297  ...     0.000788   \n",
      "962    -0.493925    -0.42616    -0.59561    0.000863  ...     0.000677   \n",
      "963    -0.437358    -0.30877    -0.55225    0.003587  ...     0.000686   \n",
      "964    -0.459456    -0.38900    -0.53714    0.001059  ...     0.000739   \n",
      "\n",
      "     LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min   LL_zmag_var  \\\n",
      "960      0.074676     -0.532664     -0.52993     -0.53521  9.585668e-07   \n",
      "961     -0.181526     -0.531169     -0.52940     -0.53365  7.608973e-07   \n",
      "962     -0.263115     -0.530569     -0.52873     -0.53222  5.160537e-07   \n",
      "963     -0.060925     -0.531167     -0.52962     -0.53283  4.975523e-07   \n",
      "964      0.335811     -0.529804     -0.52706     -0.53251  1.292131e-06   \n",
      "\n",
      "     LL_zmag_std  LL_zmag_skew   activity  people  \n",
      "960     0.000979     -0.193301  lyingBack      p1  \n",
      "961     0.000872     -0.372381  lyingBack      p1  \n",
      "962     0.000718      0.185587  lyingBack      p1  \n",
      "963     0.000705     -0.145321  lyingBack      p1  \n",
      "964     0.001137     -0.026271  lyingBack      p1  \n",
      "\n",
      "[5 rows x 272 columns]\n"
     ]
    }
   ],
   "source": [
    "lying_data = normal[(normal['activity'] == 'lyingRigh') | (normal['activity'] == 'lyingBack')]\n",
    "\n",
    "print(lying_data.dtypes)\n",
    "print(lying_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lying = lying_data.drop(columns=['activity'])  \n",
    "X_lying = lying_data.select_dtypes(include=[np.number])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_lying_scaled = scaler.fit_transform(X_lying)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 00:19:37.136571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "input_dim = X_lying_scaled.shape[1]\n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(64, activation='relu')(input_layer)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 93ms/step - loss: 1.3085 - val_loss: 1.0124\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2811 - val_loss: 0.9972\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2550 - val_loss: 0.9828\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.2282 - val_loss: 0.9681\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1994 - val_loss: 0.9526\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1679 - val_loss: 0.9360\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1351 - val_loss: 0.9181\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1017 - val_loss: 0.8991\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0693 - val_loss: 0.8794\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.0392 - val_loss: 0.8593\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0127 - val_loss: 0.8398\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9900 - val_loss: 0.8215\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9714 - val_loss: 0.8047\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9564 - val_loss: 0.7898\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9447 - val_loss: 0.7769\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9350 - val_loss: 0.7657\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9272 - val_loss: 0.7563\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9206 - val_loss: 0.7484\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9149 - val_loss: 0.7418\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9103 - val_loss: 0.7362\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9058 - val_loss: 0.7316\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.9021 - val_loss: 0.7277\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.8984 - val_loss: 0.7246\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8954 - val_loss: 0.7219\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8924 - val_loss: 0.7196\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8896 - val_loss: 0.7177\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.8870 - val_loss: 0.7161\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.8845 - val_loss: 0.7149\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.8822 - val_loss: 0.7139\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.8801 - val_loss: 0.7131\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8781 - val_loss: 0.7123\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8763 - val_loss: 0.7117\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8745 - val_loss: 0.7111\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8729 - val_loss: 0.7103\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8714 - val_loss: 0.7094\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8699 - val_loss: 0.7084\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8685 - val_loss: 0.7073\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8672 - val_loss: 0.7062\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8660 - val_loss: 0.7050\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8649 - val_loss: 0.7038\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8638 - val_loss: 0.7026\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8629 - val_loss: 0.7014\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8619 - val_loss: 0.7002\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8609 - val_loss: 0.6990\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8601 - val_loss: 0.6978\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8592 - val_loss: 0.6967\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8583 - val_loss: 0.6956\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8575 - val_loss: 0.6946\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8567 - val_loss: 0.6936\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8559 - val_loss: 0.6927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd350d628b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = models.Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(X_lying_scaled, X_lying_scaled, epochs=50, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_abnormal = abnormal.drop(columns=['activity'])\n",
    "X_abnormal = X_abnormal.select_dtypes(include=[np.number])\n",
    "X_abnormal_scaled = scaler.transform(X_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 2ms/step\n",
      "15/15 [==============================] - 0s 989us/step\n"
     ]
    }
   ],
   "source": [
    "X_lying_reconstructed = autoencoder.predict(X_lying_scaled)\n",
    "X_abnormal_reconstructed = autoencoder.predict(X_abnormal_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.19901539   0.22789352   0.1832106    0.23802488   0.21954757\n",
      "   0.19944803   0.18334948   0.16846507   0.17887697   0.2283504\n",
      "   0.1835668    0.17893518   0.21652982   0.159471     0.20457288\n",
      "   0.1779677    0.15718076   0.17471547   0.18815303   0.18263198\n",
      "   0.2185423    0.15715243   0.209622     0.4640969    0.18419509\n",
      "   0.17662752   0.18842828   0.40098588   0.63862343   0.57201331\n",
      "   0.51537121   0.18121433   0.32939599   0.30616305   0.27473608\n",
      "   0.1585754    0.18356717   0.26274837   0.22641305   0.16584027\n",
      "   0.16669435   0.18824043   0.3659204    0.19559952   0.30473384\n",
      "   0.22106128   0.51892649   0.32270955   0.4466923    0.25462974\n",
      "   0.23119675   0.15939165   0.19640017   0.19400166   0.17003141\n",
      "   0.17512031   0.179915     0.15311621   0.15556162   0.15382809\n",
      "   2.36728748 106.85911494   2.94045314   3.7191842    1.58402498\n",
      "   0.95123137   0.63311794   0.60640942   0.60863818   0.58146759\n",
      "   1.4963662    0.70547196   0.6757768    0.62523306   0.58839722\n",
      "   1.5276589    2.98984889   0.58415787   0.62217873   0.60276356\n",
      "   0.68756313   0.93585908   8.26349266  64.9485521    0.4710213\n",
      "   0.44639374   0.41466058   0.34959016   0.2958073    0.27571461\n",
      "   0.28407164   0.59177589   0.32602369   0.86784661   0.30887762\n",
      "   0.49089854   0.33739617   0.29676794   0.28407631   0.29235029\n",
      "   0.30712222   0.29096339   0.4140653    0.52085284   0.28134928\n",
      "   0.28210321   0.33804822   0.28967796   0.3083344    0.45165848\n",
      "   0.28748239   0.76749902   0.37195787   0.42716779   0.32547305\n",
      "   0.36463704   0.62317259   0.30340843   0.30466627   0.26878617\n",
      "  11.97349181  49.68207953   1.33200702   0.52466233   0.42579968\n",
      "   0.46358349   0.43500659   0.54871312   0.53504134   0.46003913\n",
      "   0.42279303   0.4451554    0.44301427   0.42038139   0.42476016\n",
      "   0.43933295   0.42138028   0.40721078   0.44884326   0.70832374\n",
      "   0.49601077   4.85090923   5.06321347   0.56471087   0.50793221\n",
      "   0.61796553   1.25604418   0.61389269   0.43115519   0.43884137\n",
      "   0.45301411   8.83721856  10.87829551   0.63569308   0.78072186\n",
      "   0.66373023   0.7622232    0.71656311   0.43050616   0.43676734\n",
      "   0.47568559   0.41131407   0.44251427   0.43861871   0.46740838\n",
      "   1.11160186   0.86817645   1.09168757   1.28501614   0.52399517\n",
      "   0.52787265   0.46236719   0.45894242   2.60466311   1.54706525\n",
      "   7.02582346   0.93751673   3.05869407   0.59161843   0.5589551\n",
      "   0.24501196   0.22854276   0.2298787    0.23809816   0.24500474\n",
      "   0.27880223   0.35568606   0.43947872   0.24725294   0.23307236\n",
      "   0.46144627   0.21470935   0.23575594   0.21280816   0.21760701\n",
      "   0.21823453   0.26993072   0.24229989   0.27231375   0.23696023\n",
      "   0.25636212   0.2755288    0.25671079   0.21036232   0.27831209\n",
      "   0.22430522   0.22747774   0.23711111   0.25381696   0.21087554\n",
      "   0.23070238   0.2470007    0.24059842   0.23785849   0.2152468\n",
      "   0.25398555   0.26399283   0.29442999   0.33090501   0.25338726\n",
      "   0.25279764   0.29627922   0.27636544   0.26798618   0.24902042\n",
      "   0.23790529   0.25569451   0.24434871   0.23868378   0.24493452\n",
      "   0.28448877   0.2784566    0.35578066   0.23869325   0.24132167\n",
      "   0.22927884   0.2328666    0.23889172   0.29566688   0.25997272\n",
      "   0.3199453    0.32764361   0.27938228   0.34953688   0.80105682\n",
      "   0.3112786    0.30508194   0.31193802   0.25723792   0.3049235\n",
      "   0.27690892   0.29548428   0.29539529   0.2986827    0.29392735\n",
      "   0.30897861   0.31694331   0.33526094   0.28894566   0.2919472\n",
      "   0.35045951   0.28745959   0.30854529   0.28365536   0.34414079\n",
      "   0.59131201   0.31987171   0.34494721   0.29397724   0.32659239\n",
      "   0.31797724   0.28160579   0.60041185   0.32540789   0.29293233\n",
      "   0.30279252   0.26352678   0.31795905   0.3150932    0.29427795\n",
      "   0.27013977   0.28703293   0.32595045   0.28807142   0.30636173\n",
      "   0.30204751   0.29542247   0.37558205   0.28933052   0.28222578\n",
      "   0.27921347   0.29133548   0.2609111    0.27399584   0.33594709\n",
      "   0.29870047   0.29385327   0.32346105   0.27104341   0.29675103\n",
      "   0.19151132   0.32078337   0.1882482    0.20319371   0.18967659\n",
      "   0.25278016   0.19132178   0.21649733   0.16329204   0.16378912\n",
      "   0.15745002   0.17429611   0.15330258   0.13949219   0.1680851\n",
      "   0.15086756   0.16194775   0.19216617   0.20218877   0.1786624\n",
      "   0.17180229   0.2029599    0.18959037   0.17127193   0.14945771\n",
      "   0.17922831   0.15487534   0.16297476   0.15972938   0.1658036\n",
      "   0.15988355   0.17015572   0.15783186   0.16649257   0.15845371\n",
      "   0.14633985   0.16241077   0.15521269   0.20175847   0.3386873\n",
      "   0.18515049   0.16487138   0.17963051   0.36827778   0.17258483\n",
      "   0.18760106   0.21769941   0.17344804   0.20062146   0.2019193\n",
      "   0.20172659   0.17324812   0.16968153   0.16548935   0.16598656\n",
      "   0.21863248   0.19008955   0.18163426   0.16901629   0.17156802\n",
      "  50.62260866   0.27324268   0.29249087   0.25013141   1.12068525\n",
      "   0.29071917   0.23197888   0.3043618    0.24062004   0.23338533\n",
      "   0.29180264   0.26455432   0.2629972    0.24295359   0.27064815\n",
      "   0.26784777   0.24973337   0.26682811   0.24355465   0.30452101\n",
      "   0.29824521   0.22194417   0.23439385   0.23117827   0.22183622\n",
      "   0.37643282   0.2375362    0.22508842   0.28256607   0.24596209\n",
      "   0.22582156   0.50486894   0.22425526   0.22104608   0.23862446\n",
      "   0.86056952   0.29292745   0.78125443   0.56149807   0.23171864\n",
      "   0.37123144   0.84197868   0.25508718   0.34658567   0.24957412\n",
      "   0.47222721   0.23239526   0.23673571   0.21971348   0.24018946\n",
      "   0.2385898    0.24770347   0.22388871   0.24443811   0.22625026\n",
      "   0.22068033   0.62924787   0.20883823   0.22733248   0.21445169\n",
      "   0.28440411   0.26921835   0.25609391   0.36897112   0.28295618\n",
      "   0.22528401   0.43560841   0.32363807   0.32405245   0.31892591\n",
      "   0.27530891   0.33339708   0.32372818   0.28683919   0.34369124\n",
      "   0.32109242   0.29000923   0.28924973   0.4177468    0.28791526\n",
      "   0.3346925    0.32771571   0.32318515   0.37509243   0.28482723\n",
      "   0.28459742   0.39246599   0.29337734   0.2916818    1.07032036\n",
      "   0.28176221   0.36054997   0.30422587   0.20132834   0.27237153\n",
      "   0.39859921   0.28003604   0.28986678   0.31986139   0.26967386\n",
      "   0.36414669   0.25799931   0.34948472   0.32313399   0.32925665\n",
      "   0.31211226   0.29836741   0.32943238   0.4064965    0.46180066\n",
      "   0.36269384   0.32181941   0.3481257    0.31040188   0.38668229\n",
      "   0.24347988   0.33236676   0.35595014   0.30659264   0.3496512\n",
      "   0.43836805   0.31474455   0.36023325   0.39613791   0.29276233\n",
      "   0.27619763   0.54443159   0.29645028   0.2835544    0.26672146\n",
      "   0.27999561   0.26960847   0.2766106    0.25444414   0.28063805\n",
      "   0.26568603   0.27558285   0.2774404    0.28688619   0.28389323\n",
      "   0.28019344   0.27663756   0.28148967   0.29590594   0.28360948\n",
      "   0.27446256   0.28493547   0.26663915   0.27994712   0.31766197\n",
      "   0.27667136   0.25784033   0.28244861   0.27938523   0.27753524\n",
      "   0.2829077    0.26152489   0.46711697   0.30487757   0.28598091\n",
      "   0.2753485    0.3035349    0.28011817   0.26678718   0.26655941\n",
      "   0.28377089   0.27889307   0.29176143   0.271009     0.26600306\n",
      "   0.27233516   0.30607554   0.25423188   0.26917992   0.27535707\n",
      "   0.26840301   0.27269214   0.26277663   0.27860694   0.27844267\n",
      "   1.59684126   0.9141644    1.0283651    0.41200916   0.32800057\n",
      "   0.37657411   0.34231376   0.33009641   0.32720857   0.55490865\n",
      "   0.39274692   0.45348213   0.54423662   1.20663814   1.84109014\n",
      "   9.68969363   4.46556467   2.95331937   1.05708756   0.48614459\n",
      "   0.39604117   0.47731721   0.31841958   0.32579089   0.32143505\n",
      "   0.37380058   0.3481207    0.35612454   1.32973298   1.70340534\n",
      "   0.41646433   0.33374504   0.60196468   0.51748939   0.32755497\n",
      "   0.34050748   0.33256516   0.32206981   0.36154479   0.34124405\n",
      "   0.32587437   0.33085564   0.30356419   0.32356624   0.32593916\n",
      "   0.32942903   0.32419601   0.32982424   0.32012991   0.3398155\n",
      "   0.32143113   0.31953124   0.32644423   0.31512985   0.4280496\n",
      "   0.84579677   0.47151063   0.33888679   0.38362051   0.32384986\n",
      "   2.41329685   0.30884921   0.30177282   0.35990217   0.37098546\n",
      "   0.31126213   0.28002952   0.2991135    0.35977226   0.2858209\n",
      "   0.29267872   0.31846996   0.30447667   0.29540974   0.29984376\n",
      "   0.30193199   0.29687114   0.30253931   0.6800309    0.54727045\n",
      "   0.28980063   0.29170437   0.291622     0.32846644   0.32357872\n",
      "   0.36795653   0.30749343   0.29345146   0.30351295   0.4235416\n",
      "   0.66229612   0.3035967    0.30733565   0.26998359   0.65228965\n",
      "   0.414149     0.65926458   0.37430464   0.30245166   0.28540059\n",
      "   0.30297744   0.29141616   0.30399487   0.29742031   0.28884636\n",
      "   0.27339491   0.30763904   0.28019737   0.27572704   0.30132669\n",
      "   2.64998281   0.39168734   0.30204616   0.27487834   0.30319851\n",
      "   0.31971524   0.34031946   0.2964945    0.30089524   0.28930073\n",
      "   0.33545453   0.32692445   0.2750816    0.36298692   0.30327688\n",
      "   0.35119573   0.26972057   0.40470819   0.54150995   0.27750509\n",
      "   0.27449772   0.96062938   0.61580583  23.26705236   0.44202362\n",
      "   0.31126637   0.28111498   0.43425583   0.30699665   0.25827463\n",
      "   0.27295507   0.26330958   0.59858883   0.31456032   0.33770388\n",
      "   0.2900943    0.31519108   0.29681257   0.4200421    0.30661895\n",
      "   0.31427041   0.30172107   0.25493392   0.24800736   0.27112556\n",
      "   0.2581574    0.29307037   0.28632751   0.29096803   0.28349772\n",
      "   0.30123029   0.35096888   0.2592451    0.27726818   0.57651086\n",
      "   0.31092722   0.28081457   0.27946888   0.26843728   0.3097003\n",
      "   0.29869355   0.25996052   0.26848584   0.2786887    0.28181486\n",
      "   0.29417985   0.297302     0.26571138   0.25907959   0.28248788\n",
      "   0.41806169   0.46024302   0.42172099   0.41171969   0.43671303\n",
      "   0.42899665   0.41246291   0.42530935   0.4039182    0.46007635\n",
      "   0.40746495   0.41153391   0.43733143   0.42987235   0.40977134\n",
      "   0.41636733   0.41864318   0.42629351   0.4406751    0.4323635\n",
      "   0.44448987   0.41709365   0.41464454   0.42637944   0.39186736\n",
      "   0.42910061   0.40050771   0.4274873    0.41819628   0.42435391\n",
      "   0.42229592   0.42036045   0.42822777   0.46169645   0.43038448\n",
      "   0.43346688   0.41805436   0.40296417   0.42307465   0.41118015\n",
      "   0.41895756   0.42203618   0.42630173   0.43064718   0.41413892\n",
      "   0.42226613   0.40882655   0.44978635   0.42292321   0.46399677\n",
      "   0.40639416   0.44220835   0.39761836   0.39276445   0.40316064\n",
      "   0.41405295   0.42388192   0.41250737   0.42393071   0.44064072\n",
      "  17.15255171   0.50659206   0.5192792    0.41169044   0.41209462\n",
      "   0.41261614   0.46933587   0.69431342   0.40168809   0.4143335\n",
      "   0.3741201    0.46473545   0.38065931   0.41667069   0.39681853\n",
      "   0.47209866   0.40354898   0.36736631   0.37747944   0.42916347\n",
      "   0.39618394   1.2525113    0.39300948   0.43135885   0.37290426\n",
      "   0.40737352   0.37813565   0.48017544   0.40097557   0.39352385\n",
      "   0.40077938   0.383446     0.37507413   0.36330775   0.38343161\n",
      "   0.48593834   0.44627397   0.43426935   0.47916769   0.41296215\n",
      "   0.63594268   0.48858493   0.45579572   0.48328802   0.387001\n",
      "   0.48835324   0.4331397    0.57640402   0.42533121   0.44937474\n",
      "   0.38114011   0.42344239   0.46482103   0.38937712   0.38614124\n",
      "   0.39695299   0.48319204   0.46430057   0.38866043   0.43845636\n",
      "  20.28070784   0.91709856   0.70343001   0.56219135   0.66935764\n",
      "   0.53000579   0.58413876   0.57504997   0.65805509   0.55034192\n",
      "   0.57964232   0.51038269   0.48808806   0.60304501   0.51423126\n",
      "   0.52668781   0.54669571   0.50048553   0.50991447   0.52035186\n",
      "   0.48226958   0.53648433   0.515476     0.52786031   0.51712581\n",
      "   0.47972393   0.48761296   0.54957256   0.48856709   0.53181693\n",
      "   0.5029947    0.48269899   0.54642071   0.49148609   0.58610486\n",
      "   0.54249758   0.68212578   0.52522324   0.53357527   0.48853797\n",
      "   0.52806284   0.47520037   0.51047348   0.52219305   0.53002928\n",
      "   0.50093977   0.50479751   0.57686766   0.50538615   0.50247524\n",
      "   0.52524802   0.48771124   0.5207196    0.61956637   0.48469156\n",
      "   0.52656572   0.51770939   0.97911049   0.52392339   0.52794416\n",
      "   0.53846238   0.51416648   0.6203603    0.58434525   0.48114124\n",
      "   0.46341143   0.49650831   0.66940601   0.51830214   0.54766986\n",
      "   0.50379735   0.57215811   0.48354673   0.54520636   0.48023144\n",
      "   0.50738043   0.5335447    0.47568927   0.48471956   0.56681263\n",
      "   0.5087466    0.56151284   0.53559201   0.51391024   0.55292084\n",
      "   0.5664929    0.50718296   0.48407599   0.49797194   0.56865609\n",
      "   0.51149412   0.54351485   0.51943278   0.44710088   0.53013825\n",
      "   0.44564847   0.52371629   0.54192466   0.5310994    0.48607991\n",
      "   0.47806385   0.5291192    0.51655965   0.50923745   0.54663323\n",
      "   0.64007271   0.43790533   0.56356374   0.46134184   0.54700725\n",
      "   0.59611608   0.53934511   0.58203033   0.57158218   0.48936783\n",
      "   0.57803195   0.5270556    0.52499008   0.56965269   0.49117054] [ 2135621.80936297  2602681.27410906  3984373.55685439  4985958.26921601\n",
      "  3416009.11823743  2503485.08518734  3696573.98817432  3331244.00275001\n",
      "  1839764.56481474  5624114.75516921  3503400.63873435  3716962.97517153\n",
      "  3667329.70952201  2739669.07156578  3259624.68511732  5862891.04177699\n",
      "  4143607.93474328  3029298.05509659  3387891.98538118  5251520.46498694\n",
      "  4921291.55871468  4392309.19366538  6863495.65504697  5507024.03450154\n",
      "  7479551.19834616  9136117.97032168  6602025.42493746  3164058.56874785\n",
      "  3787664.64454619  2578649.13371566  3876620.92381898  3729574.00196841\n",
      "  2936651.7416868   3446907.37793194  2928019.61764728  2852057.51351494\n",
      "  2530242.54805098  3383752.79505621  2830365.94762261  6114932.52586065\n",
      "  3427324.3728708   2458553.38193457  7950547.02344475  4707026.83784091\n",
      "  3119555.73169464  7051081.52424648  5516064.79749866  3347346.76988572\n",
      "  3849885.29638414  3178656.58158287  3626775.25983528  2165204.33862798\n",
      "  2758785.07113581  4698561.19068586  5304918.39558773  3634203.020083\n",
      "  2952087.9329194   6364339.84934507  3043145.93590576  5093805.86995221\n",
      "   444970.57716068   304342.30322211   299863.44425212   343514.77700983\n",
      "   187022.33755062   224441.90101843   247863.07844161   276119.97112648\n",
      "   162067.01234485   434683.69957905   283988.38871569   329836.36892156\n",
      "   360113.32848834   302404.89896911   256498.60652817   297631.44057542\n",
      "   222096.98080726   279589.70364205   296595.39540409   292291.91851032\n",
      "   115803.23045355   234457.29393983   217832.36342348   150025.98947501\n",
      "   200075.58446111   259517.27006325   129916.93760195   184716.70548069\n",
      "   195995.04961966   115224.69567786   216483.2048107     96797.05179536\n",
      "   294875.5196347    224863.60606608   125197.61912482   125120.00084001\n",
      "   208841.41842793   154263.7231642    122966.09320214   101221.78578666\n",
      "   157354.49858839   184777.3578257    286430.73406745   165159.38275322\n",
      "   303840.72759666   421128.49865366   314035.09616794   285930.96643597\n",
      "   239361.44439808   299045.23538022   401315.34988994   383993.3707597\n",
      "   247854.25678758   196104.89994126   349607.04202433   396903.159542\n",
      "   355356.42331455   454499.81109936   325190.43426684   313261.52845491\n",
      "  1689741.37711041   986718.35305482   608238.61926054   592032.46440794\n",
      "   756969.86701188   759827.46224784   481541.37464458   711055.38609213\n",
      "   257864.70936914   224999.04161475   267419.4814626    265832.91709995\n",
      "   510111.32609008   329388.77433766   565238.92993897   392630.52781933\n",
      "   417708.3271085    286435.39229577   492993.82736311   399571.12323307\n",
      "  4712640.12938459  4398286.67457342  4448326.14730848  3545786.47862955\n",
      "  2399719.23504237  1560828.38544246  2462740.0906266   2888435.01289174\n",
      "  4016972.57075679  3605669.00570073  1472394.97910136   863629.28693759\n",
      "   934379.89183416   705815.34118959   863264.88032002   893331.01384607\n",
      "   403634.67689757   489158.56395162   468970.74040892   521511.37391645\n",
      "   584759.71254633   802291.9648306    828495.58986604  1126587.37992993\n",
      "  1184786.68072261  1458441.33181239  1546829.23311459  1506911.5650677\n",
      "  3346091.31464826  1921806.02929396  1181413.37500003   647040.66648969\n",
      "  1079779.9934668   1200958.62757143  1001745.47774814   865813.18739241\n",
      "   682718.53537838  1085389.03157137  1161790.36803393   944502.26012287\n",
      "  2778033.03544623  2737717.49375645  2134935.39686453  2045959.73895431\n",
      "  2643622.61261455  2397887.77180926  2507901.31113409  2759653.21096886\n",
      "  3024823.16666034  2704987.67995231  2353189.85294868  2568583.98084719\n",
      "  2316074.79758802  2225481.31760536  2361638.43524296  2286755.2568783\n",
      "  2054271.62678033  2354631.69858495  2083638.57149815  1748710.78477408\n",
      "  1966371.29659885  2246947.57735919  2154843.78477883  1944160.48971641\n",
      "  2330834.22584406  2741575.83557625  2288028.47690934  2884280.21724965\n",
      "  2070771.73459367  2438479.39135786  3267703.17754     2322975.73035058\n",
      "  2464723.87508909  2488584.56541173  2244332.57436792  3224578.61720335\n",
      "  3074507.23358139  2600229.17566119  2580921.51976048  3060504.10775998\n",
      "  2506943.97419659  2941448.62078732  2082064.98624751  3341091.52826549\n",
      "  2492848.2091177   3469320.69671503  3058384.87952173  3024462.10045395\n",
      "  2733704.99475457  2594265.16334617  2432150.87372535  3277861.30582037\n",
      "  3058791.90119207  2366953.05394324  3157837.20889633  3379500.9147475\n",
      "  3205616.70063626  3113863.55953298  2767418.88262919  2566155.5799448\n",
      "  2006952.52402571  3567929.47193916  3424956.36697607  4135323.04425646\n",
      "  4216640.95240976  3777089.57894555  5043868.9715231   4267914.10827314\n",
      "  4649900.90412255  4928915.1235355   4324700.85010844  4035808.49522164\n",
      "  4120889.61036932  4978852.27251064  5139160.06841735  5233370.06571871\n",
      "  4875016.60556001  5419733.48593705  4478024.45530149  5133645.79067478\n",
      "  4121008.03599242  4604894.27657747  4256115.08559593  4194022.26753321\n",
      "  4583187.78178956  4354035.45630701  4555538.52101273  4189948.10815685\n",
      "  5354005.91797091  5075280.96268737  5596515.19826132  4179947.89414749\n",
      "  5437351.45292446  4643443.06419756  5434699.92883926  4561549.19332315\n",
      "  5236318.01841608  4447394.5378527   5155656.05618144  5533802.77234408\n",
      "  5413666.79882023  7071963.24942828  5725858.01253398  5927295.41976567\n",
      "  5229753.48245047  4531841.2768847   4984376.38142527  5011338.2692879\n",
      "  4979312.21141501  5265296.37686918  5554637.81474514  5636188.7036837\n",
      "  5423639.73343169  5365258.19198365  5557116.19660679  5139792.8998339\n",
      "  5446855.67668085  5180504.57691175  4417218.13298169  5335265.75711753\n",
      "   640726.23241669   644455.07764736   765577.25240344   608026.4364366\n",
      "   621257.43103875   850747.90331584   552025.71526904   446292.14516109\n",
      "   480866.74221321   456474.39729616   521392.41304142   458681.39884607\n",
      "   670108.78605557   453656.32594721   426076.61822405   523703.09785456\n",
      "   588342.63027705   547826.08559488   465370.21267081   561644.1421757\n",
      "   516001.66570713   436316.79390872   529410.7742411    856941.73786458\n",
      "   633407.9880636    678308.6656956    556769.99358666   866497.39390173\n",
      "   669504.05437535   686608.38080417   776151.20647297   951078.31652688\n",
      "   785481.18182321   476045.54908657   417225.54047454   440925.62249974\n",
      "   607486.73920913   661423.24880368   484580.01773403   604223.7998014\n",
      "   556066.8338772    680243.92409603   639633.38158948   597450.67216523\n",
      "   487685.98484689   516838.92974596   542388.50844539   466610.55140166\n",
      "   775770.11643071   716993.50623572   733261.05953865   659824.79652367\n",
      "   599065.27784561   651482.26551555   532505.063128     586910.3539882\n",
      "   679815.43697099   527591.49345009   720590.01359282   572571.97955393\n",
      "  3497815.8485199   4224123.98189843  4259336.98436833  5557752.85899023\n",
      "  4626259.39852159  4734772.65847883  4639579.56509155  7939011.44517422\n",
      "  7056254.15199261  4909376.72923526  5483571.61739398  6799745.76365016\n",
      "  4486648.84636441  5175539.80044275  5585003.72503942  4796342.9766344\n",
      "  4026073.11686336  6597020.17316429  6291044.81524651  8606598.01241408\n",
      " 12718848.13999254 22550662.20066978 17633627.3319553  11922735.65683293\n",
      "  7932491.03311574  9487171.61340697 26993127.40378054 17026625.0754768\n",
      " 11584430.15237559 10821135.7092062   8591745.00701649  8366056.43581589\n",
      " 10542451.70393694  9264367.13469876 12388696.64280319 11415072.90834893\n",
      "  4910343.31784491  4726258.28735457  3483483.74474904  4242514.92887435\n",
      "  5792920.05218673  6096747.34052192  8661754.24336901  6485165.53509444\n",
      "  7058207.74281348  7612569.56016986  8164233.44146025  7901792.01505408\n",
      "  4896728.77055439  7237489.57744787  7302634.29303252  9639458.76628299\n",
      "  7377451.88994245  4692672.86884815  7665668.31396234  7080040.58589874\n",
      "  4715980.47634178  3761320.6374195   4908668.39105629  5175185.30951748\n",
      "  2907368.6426362   2813399.3265222   2154890.74819693  1980129.43752555\n",
      "  2646137.4710696   2356614.3981541   2540957.34252123  2814725.4629578\n",
      "  2923554.00104859  2633166.46557484  2425199.99391849  2549427.1640342\n",
      "  2481992.14300327  2177142.9876993   2268853.48894011  2350082.7358552\n",
      "  1999960.65980555  2401413.12239654  2068195.62283539  1846359.62441449\n",
      "  1839913.86681686  2221243.65791704  2134773.7210532   2018619.11814331\n",
      "  2404447.64840941  2615552.50050932  2304660.54855646  2814952.48823886\n",
      "  2257440.10844457  2350146.92276565  3093085.03723237  2491748.5396068\n",
      "  2400172.57739699  2544225.20798332  2097771.85893062  3315838.30666208\n",
      "  3028646.21161806  2588094.9658823   2738982.73737003  2820100.48723338\n",
      "  2739207.29150023  2885490.94996489  2146643.45614253  3287426.67794643\n",
      "  2518841.51303196  3415699.99335652  3022819.24639502  2937129.77095673\n",
      "  2741803.09059243  2707512.34283575  2460422.86137454  3068939.04351338\n",
      "  3111527.59155775  2471706.02714437  2806803.35171782  3684739.79076626\n",
      "  3166862.07240382  3095386.11313937  2846099.922649    2543691.60941032]\n"
     ]
    }
   ],
   "source": [
    "lying_reconstruction_error = np.mean(np.square(X_lying_scaled - X_lying_reconstructed), axis=1)\n",
    "abnormal_reconstruction_error = np.mean(np.square(X_abnormal_scaled - X_abnormal_reconstructed), axis=1)\n",
    "print(lying_reconstruction_error, abnormal_reconstruction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(lying_reconstruction_error, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = np.concatenate([np.zeros(len(lying_reconstruction_error)), np.ones(len(abnormal_reconstruction_error))])\n",
    "y_pred = np.concatenate([\n",
    "    (lying_reconstruction_error > threshold).astype(int),\n",
    "    (abnormal_reconstruction_error > threshold).astype(int)\n",
    "])\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
